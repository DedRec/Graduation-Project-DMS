{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1I4Q6pGZo8ohQac7V9fsnsI7HqPNJqBUo","authorship_tag":"ABX9TyO5E8910YeelIp7V6ABRoKq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Commands"],"metadata":{"id":"lmiSqjhboLnq"}},{"cell_type":"markdown","source":["## Coping Backbone"],"metadata":{"id":"n2jF1wjKocLJ"}},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/315onpc/backbone /content/"],"metadata":{"id":"eGc1Yt3IfmYN","executionInfo":{"status":"ok","timestamp":1717346827921,"user_tz":-180,"elapsed":4281,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Installing Onnx"],"metadata":{"id":"F71RoK65ozR7"}},{"cell_type":"code","source":["!pip install onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBoADRdCkrT6","executionInfo":{"status":"ok","timestamp":1717346842681,"user_tz":-180,"elapsed":10514,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}},"outputId":"93514864-3dae-4c47-e7dc-057274e929c1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.16.1\n"]}]},{"cell_type":"code","source":["!pip install tensorflow-addons\n","!git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow && pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8tMb_Hekxiz","executionInfo":{"status":"ok","timestamp":1717346860192,"user_tz":-180,"elapsed":17517,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}},"outputId":"f6837341-7665-4440-f369-7b09e4ab2dcc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/611.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m501.8/611.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n","Cloning into 'onnx-tensorflow'...\n","remote: Enumerating objects: 6516, done.\u001b[K\n","remote: Counting objects: 100% (465/465), done.\u001b[K\n","remote: Compressing objects: 100% (200/200), done.\u001b[K\n","remote: Total 6516 (delta 325), reused 383 (delta 261), pack-reused 6051\u001b[K\n","Receiving objects: 100% (6516/6516), 1.98 MiB | 4.02 MiB/s, done.\n","Resolving deltas: 100% (5050/5050), done.\n","Obtaining file:///content/onnx-tensorflow\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (1.16.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (6.0.1)\n","Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (0.23.0)\n","Requirement already satisfied: tensorflow_probability in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (0.23.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (1.25.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (3.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons->onnx-tf==1.10.0) (24.0)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons->onnx-tf==1.10.0) (2.13.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.4.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.16.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (4.4.2)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (2.2.1)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (0.5.4)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (0.1.8)\n","Installing collected packages: onnx-tf\n","  Running setup.py develop for onnx-tf\n","Successfully installed onnx-tf-1.10.0\n"]}]},{"cell_type":"code","source":["#!pip install tensorrt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SWrXh7YYlr6u","executionInfo":{"status":"ok","timestamp":1710612593203,"user_tz":-120,"elapsed":90332,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}},"outputId":"f0589003-461f-4d54-a665-8f9f166ee1e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorrt\n","  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: tensorrt\n","  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorrt: filename=tensorrt-8.6.1.post1-py2.py3-none-any.whl size=17281 sha256=67f4926de89fbd401eeb8c6864f102a3041094eeadb76bdf0ac6927e32ac7069\n","  Stored in directory: /root/.cache/pip/wheels/f4/c8/0e/b79b08e45752491b9acfdbd69e8a609e8b2ed7640dda5a3e59\n","Successfully built tensorrt\n","Installing collected packages: tensorrt\n","Successfully installed tensorrt-8.6.1.post1\n"]}]},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"lZnne4SIpRML"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"jIcG3i4fa8PK","executionInfo":{"status":"ok","timestamp":1717347082404,"user_tz":-180,"elapsed":7,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}}},"outputs":[],"source":["from backbone.repvgg import get_RepVGG_func_by_name\n","from backbone.repvgg import repvgg_model_convert\n","from backbone.efficientnet_lite import build_efficientnet_lite\n","#import tensorrt as trt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.onnx as onnx\n","modelloc = \"/content/drive/MyDrive/effnets/eff3/Trainon300w-lpTestonBIWIbackboneefficientnet_lite3_epoch_80.tar\"\n","pthlloc = \"/content/drive/MyDrive/effnets/eff3/Trainon300w-lpTestonBIWIbackboneefficientnet_lite3_epoch_80.tar\"\n","onnxlloc =\"/content/drive/MyDrive/effnets/eff3/Trainon300w-lpTestonBIWIbackboneefficientnet_lite3_epoch_80.onnx\"\n","#engineloc=\"/content/drive/MyDrive/Model stable/runovh.engine\""]},{"cell_type":"markdown","source":["# Utils"],"metadata":{"id":"zGGDsSS4pVNm"}},{"cell_type":"code","source":["def normalize_vector(v):\n","    batch = v.shape[0]\n","    v_mag = torch.sqrt(v.pow(2).sum(1))# batch\n","    gpu = v_mag.get_device()\n","    if gpu < 0:\n","        eps = torch.autograd.Variable(torch.FloatTensor([1e-8])).to(torch.device('cpu'))\n","    else:\n","        eps = torch.autograd.Variable(torch.FloatTensor([1e-8])).to(torch.device('cuda:%d' % gpu))\n","    v_mag = torch.max(v_mag, eps)\n","    v_mag = v_mag.view(batch,1).expand(batch,v.shape[1])\n","    v = v/v_mag\n","    return v\n","\n","# u, v batch*n\n","def cross_product(u, v):\n","    batch = u.shape[0]\n","    #print (u.shape)\n","    #print (v.shape)\n","    i = u[:,1]*v[:,2] - u[:,2]*v[:,1]\n","    j = u[:,2]*v[:,0] - u[:,0]*v[:,2]\n","    k = u[:,0]*v[:,1] - u[:,1]*v[:,0]\n","\n","    out = torch.cat((i.view(batch,1), j.view(batch,1), k.view(batch,1)),1) #batch*3\n","\n","    return out\n","\n"],"metadata":{"id":"Kwb3ezhtgMRV","executionInfo":{"status":"ok","timestamp":1717346897478,"user_tz":-180,"elapsed":359,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def compute_rotation_matrix_from_ortho6d(poses):\n","    x_raw = poses[:,0:3] #batch*3\n","    y_raw = poses[:,3:6] #batch*3\n","\n","    x = normalize_vector(x_raw) #batch*3\n","    z = cross_product(x,y_raw) #batch*3\n","    z = normalize_vector(z) #batch*3\n","    y = cross_product(z,x) #batch*3\n","\n","    x = x.view(-1,3,1)\n","    y = y.view(-1,3,1)\n","    z = z.view(-1,3,1)\n","    matrix = torch.cat((x,y,z), 2) #batch*3*3\n","    return matrix"],"metadata":{"id":"_bM-lJKqgARX","executionInfo":{"status":"ok","timestamp":1717346898401,"user_tz":-180,"elapsed":10,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Model Architecture"],"metadata":{"id":"6xm0_eezpZqO"}},{"cell_type":"code","source":["class SixDRepNet(nn.Module):\n","    def __init__(self,\n","                 backbone_name, backbone_file, deploy,\n","                 pretrained=True):\n","        super(SixDRepNet, self).__init__()\n","        repvgg_fn = get_RepVGG_func_by_name(backbone_name)\n","        backbone = repvgg_fn(deploy)\n","        if pretrained:\n","            checkpoint = torch.load(backbone_file)\n","            if 'state_dict' in checkpoint:\n","                checkpoint = checkpoint['state_dict']\n","            ckpt = {k.replace('module.', ''): v for k,\n","                    v in checkpoint.items()}  # strip the names\n","            backbone.load_state_dict(ckpt)\n","            for param in backbone.parameters():\n","                param.requires_grad = False\n","        self.layer0, self.layer1, self.layer2, self.layer3, self.layer4 = backbone.stage0, backbone.stage1, backbone.stage2, backbone.stage3, backbone.stage4\n","        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n","\n","        last_channel = 0\n","        for n, m in self.layer4.named_modules():\n","            if ('rbr_dense' in n or 'rbr_reparam' in n) and isinstance(m, nn.Conv2d):\n","                last_channel = m.out_channels\n","\n","        fea_dim = last_channel\n","\n","        self.linear_reg = nn.Linear(fea_dim, 6)\n","\n","    def forward(self, x):\n","        x = self.layer0(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.gap(x)\n","        x = torch.flatten(x, 1)\n","        x = self.linear_reg(x)\n","        return compute_rotation_matrix_from_ortho6d(x)\n","\n"],"metadata":{"id":"IfL57sxjeOYL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## EfficientNet backbone"],"metadata":{"id":"9wseyqDU0MaY"}},{"cell_type":"code","source":["class SixDENet(nn.Module):\n","    def __init__(self,\n","                 backbone_name, backbone_file, deploy,\n","                 pretrained=True):\n","        super(SixDENet, self).__init__()\n","        self.backbone = build_efficientnet_lite(backbone_name,1000)\n","        in_features = self.backbone.fc.in_features\n","        self.backbone.fc = nn.Linear(in_features, 6)\n","        if pretrained and backbone_file:\n","            self.backbone.load_pretrain(backbone_file)\n","            self.backbone.eval()\n","\n","\n","    def forward(self, x):\n","        #x = self.greyscaletorgb(x)\n","        x = self.backbone(x)\n","        return compute_rotation_matrix_from_ortho6d(x)"],"metadata":{"id":"v2_XUIrQzKua","executionInfo":{"status":"ok","timestamp":1717346935641,"user_tz":-180,"elapsed":7,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Conversions"],"metadata":{"id":"_CB6VoflphXb"}},{"cell_type":"markdown","source":["## Reparameterization\n","multibranch to single branch"],"metadata":{"id":"6etYEAFYplNf"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"FAXl11HXr7Mb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714938367263,"user_tz":-180,"elapsed":6549,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}},"outputId":"c09c03e8-2af4-4f52-f5ed-bbd0a771bc96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["def load_filtered_state_dict(model, snapshot):\n","    # By user apaszke from discuss.pytorch.org\n","    model_dict = model.state_dict()\n","    snapshot = {k: v for k, v in snapshot.items() if k in model_dict}\n","    model_dict.update(snapshot)\n","    model.load_state_dict(model_dict)\n","def convert():\n","    backbone='RepVGG-AZ'\n","\n","    print('Loading model.')\n","    model = SixDRepNet(backbone_name=backbone,\n","                            backbone_file='',\n","                            deploy=False,\n","                            pretrained=False)\n","\n","    # Load snapshot\n","    saved_state_dict = torch.load(modelloc)\n","\n","    load_filtered_state_dict(model, saved_state_dict['model_state_dict'])\n","    print('Converting model.')\n","    repvgg_model_convert(model, save_path=pthlloc)\n","    print('Done.')\n","convert()\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12DkFVyOiJNw","executionInfo":{"status":"ok","timestamp":1715712950249,"user_tz":-180,"elapsed":7170,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}},"outputId":"3ce1a905-271d-4108-8513-393179d8b498"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model.\n","RepVGG Block, identity =  None\n","RepVGG Block, identity =  None\n","RepVGG Block, identity =  None\n","RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  None\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","RepVGG Block, identity =  None\n","Converting model.\n","Done.\n"]}]},{"cell_type":"markdown","source":["## Onnx Conversion\n","from pytorch to onnx format"],"metadata":{"id":"pLMZabtQp2UO"}},{"cell_type":"code","source":["# Define your PyTorch model\n","model = torch.load(pthlloc,map_location='cuda')\n","dicte = model\n","modella = SixDRepNet(backbone_name='RepVGG-AZ',\n","                        backbone_file='',\n","                        deploy=True,\n","                        pretrained=False)\n","modella.load_state_dict(dicte)\n","modella.eval()\n","\n","# Sample input (adjust according to your model's input shape)\n","dummy_input = torch.randn(1, 3, 224, 224)\n","\n","# Export the model to ONNX\n","onnx_path = onnxlloc\n","torch.onnx.export(modella, dummy_input, onnx_path, verbose=True)"],"metadata":{"id":"OVjFWXq5beTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define your PyTorch model\n","#'efficientnet_lite0': [1.0, 1.0, 224, 0.2],\n","#'efficientnet_lite1': [1.0, 1.1, 240, 0.2],\n","#'efficientnet_lite2': [1.1, 1.2, 260, 0.3],\n","#'efficientnet_lite3': [1.2, 1.4, 280, 0.3],\n","#'efficientnet_lite4'\n","# model = torch.load(pthlloc,map_location='cuda')\n","# dicte = model\n","modella = SixDENet(backbone_name='efficientnet_lite3',\n","                        backbone_file=pthlloc,\n","                        deploy=True,\n","                        pretrained=True)\n","# modella.load_state_dict(dicte)\n","modella.eval()\n","\n","# Sample input (adjust according to your model's input shape)\n","dummy_input = torch.randn(1, 3, 224, 224)\n","\n","# Export the model to ONNX\n","onnx_path = onnxlloc\n","torch.onnx.export(modella, dummy_input, onnx_path, verbose=True)"],"metadata":{"id":"RENI2jdl0VHH","executionInfo":{"status":"ok","timestamp":1717347100788,"user_tz":-180,"elapsed":7604,"user":{"displayName":"Mahmoud Omar","userId":"14055088491178907723"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## onnx to engine\n","99.5% can't be done on colab"],"metadata":{"id":"bWNYhnyCqDt0"}},{"cell_type":"code","source":["\n","\n","import onnx\n","# Load the ONNX model\n","onnx_model_path = onnxlloc\n","onnx_model = onnx.load(onnx_model_path)\n","\n","# Create a TensorRT builder and network definition\n","builder = trt.Builder(trt.Logger(trt.Logger.WARNING))\n","network = builder.create_network()\n","\n","# Parse the ONNX model into the TensorRT network\n","parser = trt.OnnxParser(network, trt.Logger(trt.Logger.WARNING))\n","parser.parse(onnx_model)\n","\n","# Set the maximum workspace size\n","workspace_size = 1 << 30  # 1GB\n","builder.set_workspace(workspace_size)\n","\n","# Build the TensorRT engine\n","builder.max_batch_size = 1\n","engine = builder.build_cuda_engine(network)\n","\n","# Save the TensorRT engine\n","trt_engine_path = engineloc\n","with open(trt_engine_path, \"wb\") as f:\n","    f.write(engine.serialize())\n"],"metadata":{"id":"B-ypwwhOcl_x"},"execution_count":null,"outputs":[]}]}